# config.py
import openai

llm_config = {
    "model": "llama3",
    "api_key": "no-key-needed",
    "base_url": "http://localhost:11434/v1",
    "temperature": 0.7,
    "max_tokens": 8192,
}
